{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1a45d0eb7191137fcbd9c8f8a3b316ec9a79bc9b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-766094a5d2f7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-766094a5d2f7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install ligthgbm\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install ligthgbm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random \n",
    "import warnings\n",
    "import operator\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "405647ff1d90a4f2aa7061dd8b6dcfce1336f398"
   },
   "source": [
    "###### def load_data():\n",
    "    loc_train = \"../input/forest-cover-type-kernels-only/train.csv\"\n",
    "    loc_test = \"../input/forest-cover-type-kernels-only/test.csv\"\n",
    "    loc_submission = \"kaggle.rf200.entropy.submission.csv\"\n",
    "    df_train = pd.read_csv(\"../input/train.csv\")\n",
    "    df_test = pd.read_csv(\"../input/test.csv\")\n",
    "    return (loc_train, loc_test, loc_submission, df_train,df_test)\n",
    "\n",
    "loc_train, loc_test, loc_submission, df_train,df_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d119133000a63e88c52d1cd6f70d4f9a12d2991"
   },
   "outputs": [],
   "source": [
    "cols_to_normalize = ['Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']\n",
    "df_train[cols_to_normalize] = normalize(df_train[cols_to_normalize])\n",
    "df_test[cols_to_normalize] = normalize(df_test[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e81565c4b3de1ebaa4c9be66c075a80d6e20937"
   },
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df_train.columns if col not in ['Cover_Type','Id']]\n",
    "feature_cols.append('binned_elevation')\n",
    "feature_cols.append('Horizontal_Distance_To_Roadways_Log')\n",
    "feature_cols.append('Soil_Type12_32')\n",
    "feature_cols.append('Soil_Type23_22_32_33')\n",
    "feature_cols.append('Horizontal_Distance_To_Hydrology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9a001492bc1e94fd750b8742501e8103986579e"
   },
   "outputs": [],
   "source": [
    "df_train['binned_elevation'] = [math.floor(v/50.0) for v in df_train['Elevation']]\n",
    "df_test['binned_elevation'] = [math.floor(v/50.0) for v in df_test['Elevation']]\n",
    "\n",
    "df_train['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_train['Horizontal_Distance_To_Roadways']]\n",
    "df_test['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_test['Horizontal_Distance_To_Roadways']]\n",
    "\n",
    "df_train['Soil_Type12_32'] = df_train['Soil_Type32'] + df_train['Soil_Type12']\n",
    "df_test['Soil_Type12_32'] = df_test['Soil_Type32'] + df_test['Soil_Type12']\n",
    "df_train['Soil_Type23_22_32_33'] = df_train['Soil_Type23'] + df_train['Soil_Type22'] + df_train['Soil_Type32'] + df_train['Soil_Type33']\n",
    "df_test['Soil_Type23_22_32_33'] = df_test['Soil_Type23'] + df_test['Soil_Type22'] + df_test['Soil_Type32'] + df_test['Soil_Type33']\n",
    "\n",
    "df_train['Horizontal_Distance_To_Hydrology_Log'] = [math.log(v+1) for v in df_train['Horizontal_Distance_To_Hydrology']]\n",
    "df_test['Horizontal_Distance_To_Hydrology_Log'] = [math.log(v+1) for v in df_test['Horizontal_Distance_To_Hydrology']]\n",
    "X_train = df_train[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "y= df_train['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67098c777212a6e84110257bcb1b2665d6b823d8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y, test_size=0.10, random_state=42, stratify=y)\n",
    "X_train.shape,y_train.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd587c397c97d47c7f30a8d950052d897fafdfd8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d92103fe91797615db23d223d483898e7566096b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_roun=25, n_folds=7, random_seed=42, n_estimators=10000, learning_rate=0.02, output_process=False,colsample_bytree=0.93,min_child_samples=56,subsample=0.84):\n",
    "    #prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight, colsample_bytree,min_child_samples,subsample):\n",
    "        params = {'application':'multiclass','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':300, 'metric':'macroF1'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"num_class\"] = 8\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        params['colsample_bytree'] = 0.93\n",
    "        params['min_child_samples'] = 56,\n",
    "        params['subsample'] = 0.84\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (19, 45),'feature_fraction': (0.1, 0.9),'bagging_fraction': (0.8, 1),'max_depth': (5, 8.99),'lambda_l1': (0, 5),'lambda_l2': (0, 3),'min_split_gain': (0.001, 0.1),'min_child_weight': (5, 50),'colsample_bytree' : (0.7,1.0),'min_child_samples' : (40,65), 'subsample' : (0.7,1.0) }, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_roun)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    # return best parameters\n",
    "    return lgbBO.res['max']['max_params']\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X_train, y_train, init_round=10, opt_roun=10, n_folds=6, random_seed=42, n_estimators=500, learning_rate=0.02,colsample_bytree=0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5137513cf9a595d31cdbab581c137bdb6cb6fb36"
   },
   "outputs": [],
   "source": [
    "opt_params = {'bagging_fraction': 0.9957236684465528,\n",
    " 'colsample_bytree': 0.7953949538181928,\n",
    " 'feature_fraction': 0.7333800304661316,\n",
    " 'lambda_l1': 1.79753950286893,\n",
    " 'lambda_l2': 1.710590311253639,\n",
    " 'max_depth': 6,\n",
    " 'min_child_samples': 48,\n",
    " 'min_child_weight': 49,\n",
    " 'min_split_gain': 0.016737988780906453,\n",
    " 'num_leaves': 33,\n",
    " 'subsample': 0.9033449610388691}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31e6b0bd351844ff9af645a5a6a83b5d22860ebf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bab5f9c1a5c757a83bca83df947d52fe752d4ce"
   },
   "outputs": [],
   "source": [
    "lgb = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000, class_weight='balanced')\n",
    "lgb.set_params(**opt_params)\n",
    "lgb.fit(X_train,y_train)\n",
    "print(lgb.score(X_train,y_train))\n",
    "y_pred = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b56bfc92d1a51796bf66862a04f54ad6db47c947"
   },
   "outputs": [],
   "source": [
    "#sub = pd.read_csv(\"../input/forest-cover-type-kernels-only/sample_submission.csv\")\n",
    "#sub.head()\n",
    "#submission = pd.DataFrame({'Id':X_test.Id,'Cover_Type':y_pred})\n",
    "#submission.to_csv('SVM_submission.csv',index=False)\n",
    "#X_test.head()\n",
    "sub = {'Id':df_test[\"Id\"].values,'Cover_Type':y_pred.astype('int')}\n",
    "sub = pd.DataFrame(data=sub)\n",
    "cols = ['Id',\"Cover_Type\"]\n",
    "sub = sub[cols]\n",
    "sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8edc8bb090b07cd2291072ff1942600a837d21d"
   },
   "outputs": [],
   "source": [
    "sub[\"Cover_Type\"] = y_pred\n",
    "sub.to_csv(\"submission_works.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb9e6c9b1ab5babf786b4dd97da2e986307c3185",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6beb92b78cd383fbf9732121c5f1375daeb7f2b0",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
