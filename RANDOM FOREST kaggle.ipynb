{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8f04d80fe7b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import seaborn as sns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingCVClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "import seaborn as sns # for making plots with seaborn\n",
    "color = sns.color_palette()\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble,model_selection,svm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "cols_to_normalize = ['Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
    "  'Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "df_train[cols_to_normalize] = normalize(df_train[cols_to_normalize])\n",
    "df_test[cols_to_normalize] = normalize(df_test[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['binned_elevation'] = [math.floor(v/50.0) for v in df_train['Elevation']]\n",
    "df_test['binned_elevation'] = [math.floor(v/50.0) for v in df_test['Elevation']]\n",
    "  \n",
    "df_train['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_train['Horizontal_Distance_To_Roadways']]\n",
    "df_test['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df_test['Horizontal_Distance_To_Roadways']]\n",
    "\n",
    "df_train['Soil_Type12_32'] = df_train['Soil_Type32'] + df_train['Soil_Type12']\n",
    "df_test['Soil_Type12_32'] = df_test['Soil_Type32'] + df_test['Soil_Type12']\n",
    "df_train['Soil_Type23_22_32_33'] = df_train['Soil_Type23'] + df_train['Soil_Type22'] + df_train['Soil_Type32'] + df_train['Soil_Type33']\n",
    "df_test['Soil_Type23_22_32_33'] = df_test['Soil_Type23'] + df_test['Soil_Type22'] + df_test['Soil_Type32'] + df_test['Soil_Type33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Elevation', 'Aspect', 'Slope',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
       "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
       "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
       "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
       "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
       "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
       "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
       "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
       "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
       "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
       "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
       "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
       "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
       "       'Cover_Type', 'binned_elevation', 'Horizontal_Distance_To_Roadways_Log',\n",
       "       'Soil_Type12_32', 'Soil_Type23_22_32_33'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df_train.columns if col not in ['Cover_Type','Id']]\n",
    "feature_cols.append('binned_elevation')\n",
    "feature_cols.append('Horizontal_Distance_To_Roadways_Log')\n",
    "feature_cols.append('Soil_Type12_32')\n",
    "feature_cols.append('Soil_Type23_22_32_33')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting in two databases in function of cover type...\n",
      "xtrain    Elevation    Aspect     Slope  Horizontal_Distance_To_Hydrology  \\\n",
      "0       2596  0.008102  0.000477                          0.040989   \n",
      "1       2590  0.008976  0.000321                          0.033980   \n",
      "2       2804  0.022641  0.001466                          0.043653   \n",
      "3       2785  0.024883  0.002890                          0.038850   \n",
      "4       2595  0.007277  0.000323                          0.024740   \n",
      "\n",
      "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
      "0                        0.000000                              510   \n",
      "1                       -0.000962                              390   \n",
      "2                        0.010587                             3180   \n",
      "3                        0.018943                             3090   \n",
      "4                       -0.000162                              391   \n",
      "\n",
      "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
      "0       0.035111        0.036858       0.023513   \n",
      "1       0.035262        0.037666       0.024203   \n",
      "2       0.038115        0.038766       0.021989   \n",
      "3       0.038208        0.038208       0.019586   \n",
      "4       0.035574        0.037838       0.024255   \n",
      "\n",
      "   Horizontal_Distance_To_Fire_Points          ...           Soil_Type39  \\\n",
      "0                            0.997552          ...                     0   \n",
      "1                            0.997755          ...                     0   \n",
      "2                            0.997010          ...                     0   \n",
      "3                            0.997096          ...                     0   \n",
      "4                            0.998023          ...                     0   \n",
      "\n",
      "   Soil_Type40  binned_elevation  Horizontal_Distance_To_Roadways_Log  \\\n",
      "0            0                51                             6.236370   \n",
      "1            0                51                             5.968708   \n",
      "2            0                56                             8.064951   \n",
      "3            0                55                             8.036250   \n",
      "4            0                51                             5.971262   \n",
      "\n",
      "   Soil_Type12_32  Soil_Type23_22_32_33  binned_elevation  \\\n",
      "0               0                     0                51   \n",
      "1               0                     0                51   \n",
      "2               1                     0                56   \n",
      "3               0                     0                55   \n",
      "4               0                     0                51   \n",
      "\n",
      "   Horizontal_Distance_To_Roadways_Log  Soil_Type12_32  Soil_Type23_22_32_33  \n",
      "0                             6.236370               0                     0  \n",
      "1                             5.968708               0                     0  \n",
      "2                             8.064951               1                     0  \n",
      "3                             8.036250               0                     0  \n",
      "4                             5.971262               0                     0  \n",
      "\n",
      "[5 rows x 62 columns]\n",
      "[1 2]\n",
      "[3 4 6]\n"
     ]
    }
   ],
   "source": [
    "print('splitting in two databases in function of cover type...')\n",
    "df_train_1_2 = df_train[(df_train['Cover_Type'] <= 2)]\n",
    "df_train_3_4_6 = df_train[(df_train['Cover_Type'].isin([3,4,6]))]\n",
    "  \n",
    "X_train = df_train[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "print('xtrain',X_train.head())\n",
    "   \n",
    "X_train_1_2 = df_train_1_2[feature_cols]\n",
    "X_train_3_4_6 = df_train_3_4_6[feature_cols]\n",
    " \n",
    "y = df_train['Cover_Type']\n",
    "y_1_2 = df_train_1_2['Cover_Type']\n",
    "y_3_4_6 = df_train_3_4_6['Cover_Type']\n",
    " \n",
    "test_ids = df_test['Id']\n",
    "del df_train\n",
    "del df_test\n",
    "  \n",
    "clf = ensemble.ExtraTreesClassifier(n_estimators=100,n_jobs=-1,random_state=0)\n",
    "clf.fit(X_train, y)\n",
    "  \n",
    "clf_1_2 = ensemble.RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=0)\n",
    "clf_1_2.fit(X_train_1_2, y_1_2)\n",
    "  \n",
    "clf_3_4_6 = ensemble.RandomForestClassifier(n_estimators=200,n_jobs=-1,random_state=0)\n",
    "clf_3_4_6.fit(X_train_3_4_6, y_3_4_6)\n",
    "  \n",
    "del X_train\n",
    "  \n",
    "vals_1_2 = {}\n",
    "for e, val in enumerate(list(clf_1_2.predict_proba(X_test))):\n",
    "   vals_1_2[e] = val\n",
    "print(clf_1_2.classes_) \n",
    "  \n",
    "vals_3_4_6 = {}\n",
    "for e, val in enumerate(list(clf_3_4_6.predict_proba(X_test))):\n",
    "   vals_3_4_6[e] = val \n",
    "print(clf_3_4_6.classes_)\n",
    "  \n",
    "vals = {}\n",
    "for e, val in enumerate(list(clf.predict(X_test))):\n",
    "  vals[e] = val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
